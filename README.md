# ğŸ  Housing Price Prediction

A machine learning project that predicts house prices using the **House Prices: Advanced Regression Techniques** dataset from Kaggle.

This notebook implements an end-to-end regression pipeline â€” from data exploration and preprocessing to training and evaluating models like **Linear Regression** and **XGBoost**.

---

## ğŸ“Œ Problem Description

Given various features of a house (like size, location, year built, and more), the goal is to build a model that can accurately predict its **sale price**.

This project focuses on:

âœ” Exploratory Data Analysis (EDA)  
âœ” Handling missing values & transformations  
âœ” Categorical encoding  
âœ” Model training and evaluation  
âœ” Performance comparison  

---

## ğŸ“ Dataset

The dataset used comes from the **Kaggle House Prices competition**:

- `train.csv` â†’ training data with labels  
- `test.csv` â†’ data to make predictions on  

You must download these files from Kaggle and place them in the same project directory.

Dataset link:  
https://www.kaggle.com/c/house-prices-advanced-regression-techniques

---

## ğŸ›  Key Steps in the Notebook

### ğŸ” 1. Exploratory Data Analysis (EDA)
- Understand target variable distribution
- Handle right skew using log transformation
- Identify relationships between features and target

### ğŸ“Š 2. Data Cleaning & Preprocessing
- Handle missing values
- Apply transformations
- Encode categorical features
  - One-Hot Encoding for nominal categories
  - Custom ordering / label encoding for ordinal relationships

### ğŸ¤– 3. Model Training
Two models were trained and evaluated:
- **Linear Regression**  
- **XGBoost Regressor**

XGBoost achieved significantly better performance.

### ğŸ” 4. Model Evaluation
Used metrics like:
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- RÂ² Score

---

## ğŸ“ˆ Results Summary

| Model              | RÂ² Score |
|-------------------|----------|
| Linear Regression | ~0.80     |
| XGBoost Regressor | ~0.91     |

XGBoost performed much better due to its ability to handle nonlinear relationships and complex interactions.

---

## ğŸ“¦ How to Run

1. Clone repository  
   ```bash
   git clone https://github.com/akashkolte/housing_price_prediction.git
2.	Download dataset files from Kaggle
3.	Place train.csv and test.csv in the project directory
4.	Open and run the notebook or use Google Colab


ğŸ“Œ Notes

âœ” No API keys or secrets are included
âœ” Outputs have been cleared for clarity
âœ” Focus on reproducibility and best practices


â¤ï¸ Author

Akash Kolte
	â€¢	MS in Computer Science (AI/ML) â€” SUNY Buffalo
	â€¢	GitHub: https://github.com/akashkolte
	â€¢	LinkedIn: https://linkedin.com/in/akash-kolte

ğŸš€ What You Can Improve
	â€¢	Hyperparameter tuning (Grid Search / Random Search)
	â€¢	Feature selection using feature importance
	â€¢	Visualization of model predictions vs actuals
	â€¢	Deployment as a web app (Streamlit / FastAPI)
