# ğŸ  Housing Price Prediction

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![ML](https://img.shields.io/badge/Machine%20Learning-Regression-green)
![Status](https://img.shields.io/badge/Status-Completed-success)
![Dataset](https://img.shields.io/badge/Dataset-Kaggle-orange)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

A machine learning project that predicts house prices using the  
**House Prices: Advanced Regression Techniques** dataset from Kaggle.

This notebook implements an end-to-end regression pipeline â€” from data exploration and preprocessing to training and evaluating models like **Linear Regression** and **XGBoost**.

---

## ğŸ“Œ Problem Description

Given various features of a house (like size, location, year built, and more), the goal is to build a model that can accurately predict its **sale price**.

This project focuses on:

âœ” Exploratory Data Analysis (EDA)  
âœ” Handling missing values & transformations  
âœ” Categorical encoding  
âœ” Model training and evaluation  
âœ” Performance comparison  

---

## ğŸ“ Dataset

Dataset: **Kaggle â€“ House Prices: Advanced Regression Techniques**

Files used:
- `train.csv` â†’ training data with labels  
- `test.csv` â†’ data to make predictions on  

Download from:  
https://www.kaggle.com/c/house-prices-advanced-regression-techniques

---

## ğŸ›  Key Steps in the Notebook

### ğŸ” 1. Exploratory Data Analysis
- Analyzed SalePrice distribution  
- Handled right skew using log transformation  
- Correlation analysis of top features  

### ğŸ“Š 2. Data Cleaning & Preprocessing
- Missing value handling  
- Feature engineering  
- Encoding:
  - One-Hot Encoding for nominal features  
  - Label Encoding for ordinal features  

### ğŸ¤– 3. Model Training
Models used:
- Linear Regression  
- XGBoost Regressor  

### ğŸ” 4. Model Evaluation
Metrics:
- RMSE  
- MAE  
- RÂ² Score  

---

## ğŸ“ˆ Results Summary

| Model              | RÂ² Score |
|-------------------|----------|
| Linear Regression | ~0.80     |
| XGBoost Regressor | ~0.91     |

XGBoost performed significantly better due to its ability to capture non-linear relationships.

---

## ğŸ“¦ How to Run

git clone https://github.com/akashkolte/housing_price_prediction.git

1.	Download dataset files from Kaggle
3.	Place train.csv and test.csv in the project directory
4.	Open and run the notebook or use Google Colab


ğŸ“Œ Notes

âœ” No API keys or secrets are included
âœ” Outputs have been cleared for clarity
âœ” Focus on reproducibility and best practices


â¤ï¸ Author

Akash Kolte
	â€¢	MS in Computer Science (AI/ML) â€” SUNY Buffalo
	â€¢	GitHub: https://github.com/akashkolte
	â€¢	LinkedIn: https://linkedin.com/in/akash-kolte

ğŸš€ What You Can Improve
	â€¢	Hyperparameter tuning (Grid Search / Random Search)
	â€¢	Feature selection using feature importance
	â€¢	Visualization of model predictions vs actuals
	â€¢	Deployment as a web app (Streamlit / FastAPI)
